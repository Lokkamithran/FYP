{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lokkamithran/FYP/blob/main/MuRIL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmQuuzzJmG2g"
      },
      "source": [
        "!pip install gpustat\n",
        "!gpustat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQEJ8IXkmTes",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6ea368e-20ca-472f-c682-c3675736edcd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hifvghb-mfeg",
        "outputId": "10ca71e0-5596-441f-b15c-e12e1dcac6f2"
      },
      "source": [
        "!pwd\n",
        "import os\n",
        "os.chdir('/content/gdrive/My Drive/FYP_Colab/MuRIL')\n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/gdrive/My Drive/FYP_Colab/MuRIL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjNwvRhbmfin",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f77ed456-3e06-44a1-df8c-e97379acd5de"
      },
      "source": [
        "!pip install bert-for-tf2\n",
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bert-for-tf2 in /usr/local/lib/python3.10/dist-packages (0.14.9)\n",
            "Requirement already satisfied: py-params>=0.9.6 in /usr/local/lib/python3.10/dist-packages (from bert-for-tf2) (0.10.2)\n",
            "Requirement already satisfied: params-flow>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from bert-for-tf2) (0.8.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.25.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.66.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwJ7igw4mfgt",
        "outputId": "19d413ee-5d2b-4e2e-a697-0a70d4c07cac"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import bert\n",
        "# from tensorflow.keras.models import Model\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import namedtuple\n",
        "from sklearn import preprocessing\n",
        "from bert import bert_tokenization\n",
        "import pickle\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "print(\"TensorFlow Version:\",tf.__version__)\n",
        "print(\"Hub version: \",hub.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow Version: 2.15.0\n",
            "Hub version:  0.16.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QixDBKKoESF"
      },
      "source": [
        "# Load train and val datasets\n",
        "df = pd.read_csv(\"../Final.csv\", sep = \"`\")\n",
        "# print(df.head())\n",
        "df['Comment'].dropna(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8 class to binary\n",
        "\n",
        "df = df.replace(to_replace=[\"Offensive_race\", \"Offensive_caste\", \"Offensive_handicapped\", \"Offensive_women\",\n",
        "                       \"Offensive_religion\", \"Offensive_sexuality\", \"Offensive_others\"], value=\"Offensive\")\n",
        "print(df['Fine Tag'].value_counts())"
      ],
      "metadata": {
        "id": "zVpAMVuvm8nC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69415fc3-190d-4b24-a20c-0ead3577e2ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine Tag\n",
            "Offensive        5159\n",
            "Not_offensive    3663\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BW-PO8F8p4HA",
        "outputId": "60b1aeec-f9b1-429b-cbdc-b4994d7d36e6"
      },
      "source": [
        "# Prepare input text and one hot encoded labels for train and validation sets\n",
        "\n",
        "unique_labels = list(np.unique(df[\"Fine Tag\"]))\n",
        "noUniqueLabels = len(unique_labels)\n",
        "\n",
        "# total_x = np.array(df[\"Comment\"])\n",
        "# total_y = np.array(df[\"Fine Tag\"])\n",
        "\n",
        "total_x = df[\"Comment\"].values\n",
        "total_y = df[\"Fine Tag\"].values\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(total_x, total_y, test_size=0.2, random_state=42)\n",
        "\n",
        "# train_x = df_train[\"text\"].values\n",
        "# train_y = df_train[\"category\"].values\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "\n",
        "# fit = le.fit(y_train)\n",
        "# y_train = fit.transform(y_train)\n",
        "\n",
        "y_fit = le.fit(y_train)\n",
        "np.save('muril_y_classes.npy', le.classes_)\n",
        "\n",
        "y_train = y_fit.transform(y_train)\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes = noUniqueLabels, dtype='float32')\n",
        "\n",
        "# val_x = df_val[\"text\"].values\n",
        "# val_y = df_val[\"category\"].values\n",
        "\n",
        "# y_test = fit.transform(y_test)\n",
        "y_test = y_fit.transform(y_test)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes = noUniqueLabels, dtype='float32')\n",
        "\n",
        "\n",
        "print(\"Number of unique labels: \", noUniqueLabels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique labels:  2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUD20x5Oqzgp",
        "outputId": "5c452625-8eb4-4c17-96a9-6ba0b5ba8e6a"
      },
      "source": [
        "# Check unique labels\n",
        "print(unique_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Not_offensive', 'Offensive']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEHX4WgmnIkM"
      },
      "source": [
        "# Function to create input_ids\n",
        "def get_ids(tokens, tokenizer, max_seq_length):\n",
        "    \"\"\"Token ids from Tokenizer vocab\"\"\"\n",
        "    token_ids = tokenizer.convert_tokens_to_ids(tokens,)\n",
        "    input_ids = token_ids + [0] * (max_seq_length-len(token_ids))\n",
        "    return input_ids\n",
        "\n",
        "# Function to create attention masks\n",
        "def get_masks(tokens, max_seq_length):\n",
        "    return [1]*len(tokens) + [0] * (max_seq_length - len(tokens))\n",
        "\n",
        "# Function to create segment ids\n",
        "def get_segments(tokens, max_seq_length):\n",
        "    \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n",
        "    segments = []\n",
        "    current_segment_id = 0\n",
        "    for token in tokens:\n",
        "        segments.append(current_segment_id)\n",
        "        if token == \"[SEP]\":\n",
        "            current_segment_id = 1\n",
        "    return segments + [0] * (max_seq_length - len(tokens))\n",
        "\n",
        "# Function to create input_ids, attention_masks, segment_ids for sample\n",
        "def create_single_input(sentence,MAX_LEN, MAX_SEQ_LEN):\n",
        "\n",
        "  stokens = tokenizer.tokenize(sentence)\n",
        "\n",
        "  stokens = stokens[:MAX_LEN]\n",
        "\n",
        "  stokens = [\"[CLS]\"] + stokens + [\"[SEP]\"]\n",
        "\n",
        "  ids = get_ids(stokens, tokenizer, MAX_SEQ_LEN)\n",
        "  masks = get_masks(stokens, MAX_SEQ_LEN)\n",
        "  segments = get_segments(stokens, MAX_SEQ_LEN)\n",
        "\n",
        "  return ids,masks,segments\n",
        "\n",
        "def create_input_array(sentences, MAX_SEQ_LEN):\n",
        "\n",
        "  input_ids, input_masks, input_segments = [], [], []\n",
        "\n",
        "  for sentence in tqdm(sentences,position=0, leave=True):\n",
        "\n",
        "    ids,masks,segments=create_single_input(sentence,MAX_SEQ_LEN-2, MAX_SEQ_LEN)\n",
        "\n",
        "    input_ids.append(ids)\n",
        "    input_masks.append(masks)\n",
        "    input_segments.append(segments)\n",
        "\n",
        "  return [np.asarray(input_ids, dtype=np.int32),\n",
        "            np.asarray(input_masks, dtype=np.int32),\n",
        "            np.asarray(input_segments, dtype=np.int32)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8AmiWuknTKL"
      },
      "source": [
        "# MuRIL model layer\n",
        "muril_layer = hub.KerasLayer(\"https://tfhub.dev/google/MuRIL/1\", trainable=True)\n",
        "\n",
        "# Create tokenizer\n",
        "vocab_file = muril_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = muril_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = bert_tokenization.FullTokenizer(vocab_file, do_lower_case)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDqjXUqturNk",
        "outputId": "cf414837-52c9-4775-e3f7-cb96c710410f"
      },
      "source": [
        "# Create input_ids, attention_masks, segment_ids for training and validation sets with max_seq_len as 128\n",
        "max_seq_len = 128\n",
        "x_train_array = create_input_array(x_train, max_seq_len)\n",
        "x_test_array = create_input_array(x_test, max_seq_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7057/7057 [00:04<00:00, 1570.04it/s]\n",
            "100%|██████████| 1765/1765 [00:01<00:00, 1291.98it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(x_train[0])\n",
        "# print(x_train_array[2][0])"
      ],
      "metadata": {
        "id": "1Ut6drApdVY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtImk-2eqn4a"
      },
      "source": [
        "# Define model function - compile and fit\n",
        "def model_fit(train_x, train_y, val_x, val_y, max_seq_length, num_epochs, muril_layer):\n",
        "\n",
        "  input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
        "                                       name=\"input_word_ids\")\n",
        "  input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
        "                                   name=\"input_mask\")\n",
        "  segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
        "                                    name=\"segment_ids\")\n",
        "\n",
        "  outputs = muril_layer(dict(input_word_ids = input_word_ids, input_mask = input_mask, input_type_ids = segment_ids))\n",
        "\n",
        "  x = tf.keras.layers.Dropout(0.1)(outputs[\"pooled_output\"]) # take pooled output layer\n",
        "\n",
        "#   print(x[0])\n",
        "#   print(x[1])\n",
        "\n",
        "  final_output = tf.keras.layers.Dense(noUniqueLabels, activation=\"softmax\")(x)\n",
        "\n",
        "  model = tf.keras.models.Model(\n",
        "      inputs=[input_word_ids, input_mask, segment_ids], outputs=final_output)\n",
        "\n",
        "  model.compile(loss='binary_crossentropy',\n",
        "                  optimizer = tf.keras.optimizers.Adam(learning_rate=1e-1),\n",
        "                  metrics=['accuracy'])\n",
        "  model.fit(train_x, train_y, epochs = num_epochs, batch_size = 32, validation_data = (val_x, val_y), shuffle = True)\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfQ_Jv6sulcq",
        "outputId": "a7d22b79-f81a-45c7-d8ff-6caa587904d6"
      },
      "source": [
        "# Set number of epochs\n",
        "num_epochs = 1\n",
        "\n",
        "# Get the model object\n",
        "model = model_fit(x_train_array, y_train, x_test_array, y_test, max_seq_len, num_epochs, muril_layer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "221/221 [==============================] - 258s 942ms/step - loss: 3.4678 - accuracy: 0.5201 - val_loss: 1.0091 - val_accuracy: 0.3972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8Y7dCzfrDJT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7dd70fb-8a72-4619-a3cf-0e12b28c3d4d"
      },
      "source": [
        "# Make predictions\n",
        "preds = model.predict(x_test_array)\n",
        "preds = np.argmax(preds, axis=1)\n",
        "print(preds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "56/56 [==============================] - 15s 265ms/step\n",
            "[1 1 1 ... 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(model, open('muril_model.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "xhC10YousKVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickled_model = pickle.load(open('muril_model.pkl', 'rb'))"
      ],
      "metadata": {
        "id": "ICKAKwL4saNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "new_preds = pickled_model.predict(x_test_array)\n",
        "new_preds = np.argmax(preds, axis=1)\n",
        "print(new_preds)"
      ],
      "metadata": {
        "id": "ES0WFae7slyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(y_test)\n",
        "# y_test = np.argmax(y_test, axis=1)\n",
        "# preds = new_preds\n",
        "\n",
        "accuracy = accuracy_score(y_test, preds)\n",
        "f1 = f1_score(y_test, preds, average='weighted')\n",
        "\n",
        "print(accuracy)\n",
        "print(f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLgAurIvJN5m",
        "outputId": "23e4c073-2979-463d-8219-bcbe3d45d2df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5809011051289317\n",
            "0.42690348288736685\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = len(y_test)\n",
        "\n",
        "for i in range(0, len(preds)):\n",
        "    if(y_test[i][np.argmax(preds[i])] == 1):\n",
        "        correct += 1\n",
        "\n",
        "print(\"Test accuracy: \", round(correct/total, 4))\n",
        "\n",
        "#Test accuracy for multinary doesn't seem to exceed .4915\n",
        "#And it also predicts the same vector for EVERY test comment with the highest prob. for \"Not_offensive\"\n",
        "\n",
        "#And .5515 for binary classification with 0.001 lr :(\n",
        "#.4522 with 0.1 learning rate for Adam"
      ],
      "metadata": {
        "id": "00au7eXBhG8K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0da12389-c8a3-4f75-d39f-fb59f869b54b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy:  0.5809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(x_test[1], \" \", y_test[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-t2w0VGo378",
        "outputId": "b284595f-948c-4a4e-c317-42be2d9bd665"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trailer la vidya balan missing.... why?   [1. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    }
  ]
}