{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP81FkKKX+Rqim1Wmsh5pkZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lokkamithran/FYP/blob/main/SVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "XFjOWlzUkOuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "import os\n",
        "os.chdir('/content/gdrive/My Drive/FYP_Colab/SVM')\n",
        "!pwd"
      ],
      "metadata": {
        "id": "Z2IWIIf0kclg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ol4JYjdkIHL"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from collections import defaultdict\n",
        "from nltk.corpus import wordnet as wn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn import model_selection, naive_bayes, svm\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
        "import nltk\n",
        "import pickle\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mapping(prediction):\n",
        "    # if prediction == 0:\n",
        "    #     output = \"not offensive.\"\n",
        "    if prediction == 0:\n",
        "        output = \"offensive to other castes.\"\n",
        "    elif prediction == 1:\n",
        "        output = \"offensive to handicapped people.\"\n",
        "    elif prediction == 2:\n",
        "        output = \"offensive to others.\"\n",
        "    elif prediction == 3:\n",
        "        output = \"racially offensive.\"\n",
        "    elif prediction == 4:\n",
        "        output = \"offensive to other religions.\"\n",
        "    elif prediction == 5:\n",
        "        output = \"offensive to people of the LGBTQIA+ community.\"\n",
        "    else:\n",
        "        output = \"offensive to women.\"\n",
        "    return output\n"
      ],
      "metadata": {
        "id": "OZ1vj3OIB0ju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calMetric(y_test, pred):\n",
        "    accuracy = accuracy_score(y_test, pred)\n",
        "    f1 = f1_score(y_test, pred, average='weighted')\n",
        "    recall = recall_score(y_test, pred, average = 'weighted')\n",
        "    precision = precision_score(y_test, pred, average = 'weighted')\n",
        "    return [round(accuracy, 3), round(f1, 3), round(recall, 3), round(precision, 3)]"
      ],
      "metadata": {
        "id": "FCT-bRd8fcFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_rbf(x_train, x_test, y_train, y_test):\n",
        "\n",
        "    start = time.process_time()\n",
        "    rbf = svm.SVC(kernel = 'rbf', gamma = 1, C = 1).fit(x_train, y_train)\n",
        "    end = time.process_time()\n",
        "    pred = rbf.predict(x_test)\n",
        "\n",
        "    return [calMetric(y_test, pred)]\n",
        "#1, 1 - 91, 90.8"
      ],
      "metadata": {
        "id": "DYv0P_b7lC3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_poly(x_train, x_test, y_train, y_test):\n",
        "    poly = svm.SVC(kernel = 'poly', degree = 4, C = 10).fit(x_train, y_train)\n",
        "    pred = poly.predict(x_test)\n",
        "\n",
        "    return calMetric(y_test, pred)"
      ],
      "metadata": {
        "id": "0PYS4HVcfzEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load train and val datasets\n",
        "df = pd.read_csv(\"../Final.csv\", sep = \"`\")\n",
        "# print(df.head())\n",
        "df['Comment'].dropna(inplace=True)\n",
        "\n",
        "df = df[df['Fine Tag'] != 'Not_offensive']\n",
        "\n",
        "x = df[\"Comment\"].values\n",
        "y = df[\"Fine Tag\"].values\n",
        "# x_train, x_test, y_train, y_test = model_selection.train_test_split(x, y, test_size=0.20, random_state = 42)\n",
        "# print(df['Fine Tag'].value_counts())"
      ],
      "metadata": {
        "id": "4b2yfWq0keAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rbf_df = pd.DataFrame(columns=['k','Test Partition No.','Accuracy','Precision','Recall','F1 Score', 'Training Time'])\n",
        "poly_df = pd.DataFrame(columns=['k','Test Partition No.','Accuracy','Precision','Recall','F1 Score'])"
      ],
      "metadata": {
        "id": "Dgk1j2RokqRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = 5\n",
        "k_fold = KFold(n_splits = k)\n",
        "rbf_metrics = []\n",
        "poly_metrics = []\n",
        "i = 1\n",
        "\n",
        "for training_index, testing_index in k_fold.split(x):\n",
        "    x_train, x_test = x[training_index], x[testing_index]\n",
        "    y_train, y_test = y[training_index], y[testing_index]\n",
        "\n",
        "    vectorizer = TfidfVectorizer(max_features = int(1e5))\n",
        "    fitted_vec = vectorizer.fit(x_train)\n",
        "    x_train = fitted_vec.transform(x_train)\n",
        "    x_test = fitted_vec.transform(x_test)\n",
        "\n",
        "    encoder = LabelEncoder()\n",
        "    fitted_encoder = encoder.fit(y_train)\n",
        "    y_train = fitted_encoder.transform(y_train)\n",
        "    y_test = fitted_encoder.transform(y_test)\n",
        "\n",
        "    oversample = SMOTE(sampling_strategy = 'not majority')\n",
        "    x_train, y_train = oversample.fit_resample(x_train, y_train)\n",
        "\n",
        "    # rbf_results = fit_rbf(x_train, x_test, y_train, y_test)\n",
        "    # rbf_acc, rbf_f1, rbf_recall, rbf_precision = rbf_results[0]\n",
        "    # rbf_ttime = rbf_results[1]\n",
        "    # rbf_metrics.append([rbf_acc, rbf_f1, rbf_recall, rbf_precision, rbf_ttime])\n",
        "    # rbf_df.loc[len(rbf_df.index)] = [k, i, rbf_acc, rbf_precision, rbf_recall, rbf_f1, rbf_ttime]\n",
        "    # print(rbf_metrics)\n",
        "\n",
        "    poly_acc, poly_f1, poly_recall, poly_precision = fit_poly(x_train, x_test, y_train, y_test)\n",
        "    poly_metrics.append([poly_acc, poly_f1, poly_recall, poly_precision])\n",
        "    poly_df.loc[len(poly_df.index)] = [k, i, poly_acc, poly_precision, poly_recall, poly_f1]\n",
        "    print(poly_metrics)\n",
        "\n",
        "    print(\"\\n\\n\")\n",
        "    i += 1\n",
        "\n",
        "# rbf_df.to_excel(excel_writer = r'RBF Metrics k=5.xlsx', index=False)\n",
        "poly_df.to_excel(excel_writer = r'Poly Metrics k=5.xlsx', index=False)"
      ],
      "metadata": {
        "id": "YHNjG56xSF3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(rbf_results[0])"
      ],
      "metadata": {
        "id": "6qRR78vkKMMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Tfidf_vect = TfidfVectorizer(max_features=100000)\n",
        "\n",
        "fit = Tfidf_vect.fit(x)\n",
        "# np.save('svm_x_classes.npy', fit.get_feature_names_out())\n",
        "\n",
        "x = fit.transform(x)\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "y_fit = encoder.fit(y)\n",
        "y = y_fit.transform(y)\n",
        "\n",
        "# print(encoder.classes_)\n",
        "# print(encoder.transform(encoder.classes_))\n",
        "\n",
        "oversample = SMOTE(sampling_strategy = 'not majority')\n",
        "x, y = oversample.fit_resample(x, y)\n",
        "\n",
        "# unique, frequency = np.unique(y, return_counts = True)\n",
        "# print(unique)\n",
        "# print(frequency)\n",
        "\n",
        "x_train, x_test, y_train, y_test = model_selection.train_test_split(x, y, test_size=0.20, random_state = 42)"
      ],
      "metadata": {
        "id": "mjHy9vF8-aK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "X = [20, 40, 60, 80]\n",
        "\n",
        "plt.plot(X, acc_list, color='r', label='test-accuracy')\n",
        "# plt.plot(X, f1_list, color='g', label='f1-score')\n",
        "\n",
        "plt.xlabel(\"% Training Data\")\n",
        "plt.ylabel(\"F1 Score\")\n",
        "# plt.title(\"F1 Score of SVM polynomial\")\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "noMKci0-TZb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sum(acc_list)/len(acc_list))"
      ],
      "metadata": {
        "id": "b2S5ymNzVYsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(rbf, open('rbf_only_offensive.pkl', 'wb'))\n",
        "pickle.dump(fit, open(\"tfidf.pickle\", \"wb\"))"
      ],
      "metadata": {
        "id": "FJ_kzLo7GuB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#rbf accuracy\n",
        "# rbf_pred = new_pred\n",
        "\n",
        "rbf_accuracy = accuracy_score(y_test, rbf_pred)\n",
        "rbf_f1 = f1_score(y_test, rbf_pred, average='weighted')\n",
        "rbf_recall = recall_score(y_test, rbf_pred, average = 'weighted')\n",
        "rbf_precision = precision_score(y_test, rbf_pred, average = 'weighted')\n",
        "\n",
        "print('Accuracy (RBF Kernel): ', \"%.2f\" % (rbf_accuracy*100))\n",
        "print('F1 (RBF Kernel): ', \"%.2f\" % (rbf_f1*100))\n",
        "print('Recall (RBF Kernel): ', '%.2f' % (rbf_recall*100))\n",
        "print('Precision (RBF Kernel): ', '%.2f' % (rbf_precision*100))"
      ],
      "metadata": {
        "id": "TEyhaKlblath"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poly = svm.SVC(kernel = 'poly', degree = 4, C = 10).fit(x_train, y_train)\n",
        "poly_pred = poly.predict(x_test)\n",
        "\n",
        "#4, 10 - 77, 73"
      ],
      "metadata": {
        "id": "ot6EVCJfzj4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(poly, open('poly_only_offensive.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "6TlQ_4PoIdqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Poly accuracy\n",
        "poly_accuracy = accuracy_score(y_test, poly_pred)\n",
        "poly_f1 = f1_score(y_test, poly_pred, average='weighted')\n",
        "poly_recall = recall_score(y_test, poly_pred, average = 'weighted')\n",
        "poly_precision = precision_score(y_test, poly_pred, average = 'weighted')\n",
        "\n",
        "print('Accuracy (Polynomial Kernel): ', \"%.2f\" % (poly_accuracy))\n",
        "print('F1 (Polynomial Kernel): ', \"%.2f\" % (poly_f1))\n",
        "print('Recall (Poly Kernel): ', '%.2f' % (poly_recall))\n",
        "print('Precision (Poly Kernel): ', '%.2f' % (poly_precision))"
      ],
      "metadata": {
        "id": "n6onZO67lVme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# import pickle\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "\n",
        "pickled_model = pickle.load(open('poly_only_offensive.pkl', 'rb'))\n",
        "\n",
        "Tfidf_vect_new = TfidfVectorizer(max_features=100000)\n",
        "Tfidf_vect_new = pickle.load(open('tfidf.pickle', 'rb'))\n",
        "# new_pred = pickled_model.predict(x_test)\n",
        "\n",
        "# print(new_pred)"
      ],
      "metadata": {
        "id": "AuFhzpdhH8cC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poly_pred = pickled_model.predict(x_test)"
      ],
      "metadata": {
        "id": "6qBjFJvZDzEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentence = \"nee laam uyir vaala ve kudathu\"\n",
        "test_sentence = Tfidf_vect_new.transform([test_sentence])\n",
        "\n",
        "prediction = pickled_model.predict(test_sentence)[0]\n",
        "print(\"This statement is\", mapping(prediction))"
      ],
      "metadata": {
        "id": "wPatFh1E9P_t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
